{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d163b548",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo  import MongoClient\n",
    "from wordcloud import WordCloud\n",
    "import pandas as pd\n",
    "import re\n",
    "import collections\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import string\n",
    "import scipy.stats as st\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn import decomposition, naive_bayes, preprocessing, model_selection, metrics\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from tqdm.notebook import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3a6d84",
   "metadata": {},
   "source": [
    "### Connexion à la bdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fc99ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient(host=\"localhost\", port=27017)\n",
    "db = client[\"PLDAC\"]\n",
    "collection = db[\"avis\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6105b9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(collection.find()))\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1704d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_users = len(df[\"author\"].unique())\n",
    "num_items = len(df[\"title\"].unique())\n",
    "\n",
    "print(f\"there are {num_users} authors and {num_items} items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c49385",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85ccc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsity = (len(df)/(num_items * num_users))*100\n",
    "print(f\"Rating matrix is only {sparsity}% full\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23cd218",
   "metadata": {},
   "source": [
    "### Repartition des notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bcb58f2",
   "metadata": {},
   "source": [
    "Find the count/mean/std/min/max of the notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0308809f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['note'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178a201a",
   "metadata": {},
   "source": [
    "Skewness empirique, mesure d'asymétrie:\n",
    "\n",
    "L'asymétrie d'une distribution traduit la régularité ou non avec laquelle les observations se répartissent autour de la valeur centrale\n",
    "\n",
    "skew = 0 -> symetrique \n",
    "\n",
    "skew < 0 -> dstn étalée à gauche (oblique à droite) -> mean < median < mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9233d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['note'].skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d2a504",
   "metadata": {},
   "outputs": [],
   "source": [
    "median = df['note'].median()\n",
    "mean = df['note'].mean()\n",
    "variance = df['note'].var()\n",
    "std = df['note'].std()\n",
    "print(\"mediane : \", median)\n",
    "print(\"moyenne : \", mean)\n",
    "print(\"variance : \", variance)\n",
    "print(\"ecart-type : \", std)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4ecec3",
   "metadata": {},
   "source": [
    "Distribution globale des notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455619fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df[\"note\"], bins=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6659c3a",
   "metadata": {},
   "source": [
    "Distribution des notes par autheurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5a1d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_means = df.groupby(\"author\")[\"note\"].mean()\n",
    "sns.distplot(user_means,bins=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bdfb35",
   "metadata": {},
   "source": [
    "Distribution des notes par jeux\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81555ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_means = df.groupby(\"title\")[\"note\"].mean()\n",
    "sns.distplot(item_means,bins=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21497e79",
   "metadata": {},
   "source": [
    "Built Train/ Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b820dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indexes,test_indexes = [],[]\n",
    "\n",
    "for index in range(len(df)):\n",
    "    if index%5 == 0:\n",
    "        test_indexes.append(index)\n",
    "    else:\n",
    "        train_indexes.append(index)\n",
    "\n",
    "train_df = df.iloc[train_indexes].copy()\n",
    "test_df = df.iloc[test_indexes].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f41ecc",
   "metadata": {},
   "source": [
    "Global Training Mean, Global User Mean, Global Item Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df69b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "MEAN = train_df[\"note\"].mean()\n",
    "USER_MEANS = train_df.groupby(\"author\")[\"note\"].mean()\n",
    "ITEM_MEANS = train_df.groupby(\"title\")[\"note\"].mean()\n",
    "\n",
    "\n",
    "def mean_rating_pred(user_item):\n",
    "    user = user_item[\"author\"]\n",
    "    item = user_item[\"title\"]\n",
    "    \n",
    "    return MEAN\n",
    "\n",
    "def user_mean_rating_pred(user_item):\n",
    "    user = user_item[\"author\"]\n",
    "    item = user_item[\"title\"]\n",
    "    \n",
    "    return USER_MEANS.get(user,default=MEAN)\n",
    "\n",
    "def item_mean_rating_pred(user_item):\n",
    "    user = user_item[\"author\"]\n",
    "    item = user_item[\"title\"]\n",
    "    \n",
    "    return ITEM_MEANS.get(item,default=MEAN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1ff9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\"mean_prediction\"] = test_df[[\"author\",\"title\"]].apply(mean_rating_pred,axis=1)\n",
    "test_df[\"muser_prediction\"] = test_df[[\"author\",\"title\"]].apply(user_mean_rating_pred,axis=1) \n",
    "test_df[\"mitem_prediction\"] = test_df[[\"author\",\"title\"]].apply(item_mean_rating_pred,axis=1) \n",
    "\n",
    "test_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669579c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "details = db[\"details\"]\n",
    "df_details = pd.DataFrame(list(details.find()))\n",
    "df_details.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951427ba",
   "metadata": {},
   "source": [
    "### Jeux les mieux notés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81288062",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_details.sort_values(by='Note', ascending=False, inplace=True)\n",
    "df_details[['titre', 'Note']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a616992a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = pd.DataFrame()\n",
    "titres = list(df_details.titre)\n",
    "for i in range(1, 11):\n",
    "    tmp_df[f'{1 + (i - 1) * 10} - {i * 10}'] = titres[((i-1)*10) : i*10]\n",
    "tmp_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9b1ab4",
   "metadata": {},
   "source": [
    "### Jeux avec le plus d'avis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce94721",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_details.sort_values(by='Nombre d\\'avis', ascending=False, inplace=True)\n",
    "df_details[['titre', 'Nombre d\\'avis']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85530aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = pd.DataFrame()\n",
    "titres = list(df_details.titre)\n",
    "for i in range(1, 11):\n",
    "    tmp_df[f'{1 + (i - 1) * 10} - {i * 10}'] = titres[((i-1)*10) : i*10]\n",
    "tmp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ca402f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2610c8ca",
   "metadata": {},
   "source": [
    "### Vocabulaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38578f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.copy()\n",
    "df['comment'] = df['comment'].astype(str)\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(df.comment)\n",
    "\n",
    "print('Taille initiale du vocabulaire :', len(vectorizer.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7aec57",
   "metadata": {},
   "outputs": [],
   "source": [
    "wc = WordCloud(background_color=\"white\").generate(' '.join(vectorizer.vocabulary_.keys()))\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.title('Vocabulaire initial')\n",
    "plt.imshow(wc, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58e7c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "wc = WordCloud().generate(' '.join(df.comment))\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.title('Word cloud corpus')\n",
    "plt.imshow(wc, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0acf68e7",
   "metadata": {},
   "source": [
    "### 100 mots les plus frequents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b14a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = \" \".join(df.comment).split()\n",
    "word_counter = Counter(words)\n",
    "\n",
    "top_100_words = dict(word_counter.most_common(100))\n",
    "\n",
    "wc = WordCloud().generate_from_frequencies(top_100_words)\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.title('Word cloud 100 mots les plus fréquents')\n",
    "plt.imshow(wc, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e174a27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = pd.DataFrame()\n",
    "top_100_words = list(top_100_words)\n",
    "for i in range(1, 11):\n",
    "    tmp_df[f'{1 + (i - 1) * 10} - {i * 10}'] = top_100_words[((i-1)*10) : i*10]\n",
    "tmp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c2bfd3",
   "metadata": {},
   "source": [
    "### Bigramme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffacc979",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(2,2))\n",
    "X = vectorizer.fit_transform(df.comment)\n",
    "\n",
    "bigram_frequencies = np.array(X.sum(axis=0))[0]\n",
    "bigram_frequencies_sorted = (-bigram_frequencies).argsort()\n",
    "\n",
    "features = vectorizer.get_feature_names_out()\n",
    "\n",
    "top_100_bigrams_df = pd.DataFrame()\n",
    "top_100_bigrams_df['bigram'] = [features[i] for i in bigram_frequencies_sorted[:100]]\n",
    "top_100_bigrams_df['frequency'] = [bigram_frequencies[i] for i in bigram_frequencies_sorted[:100]]\n",
    "top_100_bigrams_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df16367b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = pd.DataFrame()\n",
    "bigrams = list(top_100_bigrams_df.bigram)\n",
    "for i in range(1, 11):\n",
    "    tmp_df[f'{1 + (i - 1) * 10} - {i * 10}'] = bigrams[((i-1)*10) : i*10]\n",
    "tmp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1e0481",
   "metadata": {},
   "source": [
    "### Trigramme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d56ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(3,3))\n",
    "X = vectorizer.fit_transform(df.comment)\n",
    "\n",
    "trigram_frequencies = np.array(X.sum(axis=0))[0]\n",
    "trigram_frequencies_sorted = (-trigram_frequencies).argsort()\n",
    "\n",
    "features = vectorizer.get_feature_names_out()\n",
    "\n",
    "top_100_trigrams_df = pd.DataFrame()\n",
    "top_100_trigrams_df['trigram'] = [features[i] for i in trigram_frequencies_sorted[:100]]\n",
    "top_100_trigrams_df['frequency'] = [trigram_frequencies[i] for i in trigram_frequencies_sorted[:100]]\n",
    "top_100_trigrams_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb4b454",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = pd.DataFrame()\n",
    "trigrams = list(top_100_trigrams_df.trigram)\n",
    "for i in range(1, 11):\n",
    "    tmp_df[f'{1 + (i - 1) * 10} - {i * 10}'] = trigrams[((i-1)*10) : i*10]\n",
    "tmp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2e9420",
   "metadata": {},
   "source": [
    "### stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8673f2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "stops_words_french = stopwords.words('french')\n",
    "others_stops_words = [\"a\", \"as\", \"ai\", \"au\", \"aux\", \"avec\", \"ce\", \"ces\", \"dans\", \"de\", \"des\",\n",
    "                      \"du\", \"elle\", \"en\", \"et\", \"eux\", \"il\", \"je\", \"la\", \"le\", \"leur\", \"lui\", \n",
    "                      \"ma\", \"mais\", \"me\", \"même\", \"mes\", \"moi\", \"mon\", \"ne\", \"nos\", \"notre\", \n",
    "                      \"nous\", \"on\", \"ou\", \"par\", \"pas\", \"pour\", \"qu\", \"que\", \"qui\", \"sa\", \"se\", \n",
    "                      \"ses\", \"son\", \"sur\", \"ta\", \"te\", \"tes\", \"toi\", \"ton\", \"tu\", \"un\", \"une\", \n",
    "                      \"vos\", \"votre\", \"vous\", \"c\", \"d\", \"j\", \"l\", \"à\", \"m\", \"n\", \"s\", \"t\", \"y\", \n",
    "                      \"été\", \"étée\", \"étées\", \"étés\", \"étant\", \"suis\", \"es\", \"est\", \"sommes\", \"êtes\", \n",
    "                      \"sont\", \"serai\", \"seras\", \"sera\", \"serons\", \"serez\", \"seront\", \"serais\", \"serait\", \n",
    "                      \"serions\", \"seriez\", \"seraient\", \"étais\", \"était\", \"étions\", \"étiez\", \n",
    "                      \"étaient\", \"fus\", \"fut\", \"fûmes\", \"fûtes\", \"furent\", \"sois\", \"soit\", \n",
    "                      \"soyons\", \"soyez\", \"soient\", \"fusse\", \"fusses\", \"fût\", \"fussions\", \n",
    "                      \"fussiez\", \"fussent\", \"ayant\", \"eu\", \"eue\", \"eues\", \"eus\", \"ai\", \"as\", \n",
    "                      \"avons\", \"avez\", \"ont\", \"aurai\", \"auras\", \"aura\", \"aurons\", \"aurez\", \n",
    "                      \"auront\", \"aurais\", \"aurait\", \"aurions\", \"auriez\", \"auraient\", \"avais\", \n",
    "                      \"avait\", \"avions\", \"aviez\", \"avaient\", \"eut\", \"eûmes\", \"eûtes\", \"eurent\", \n",
    "                      \"aie\", \"aies\", \"ait\", \"ayons\", \"ayez\", \"aient\", \"eusse\", \"eusses\", \"eût\", \n",
    "                      \"eussions\", \"eussiez\", \"eussent\",\n",
    "                      #\n",
    "                      \"comme\", \"comment\", \"cependant\", \"parce\", \"dont\", \"aussi\", \"cette\",\n",
    "                      \"aujourd\", \"hui\", \"dont\", \"ceci\", \"cela\", \"celle\", \"celui\", \"ceux\", \"celles\",\n",
    "                      \"pourquoi\", \"quand\", \"tout\", \"toute\", \"tous\", \"toutes\"]\n",
    "stops_words_french = sorted( list( set(stops_words_french + others_stops_words) ) )\n",
    "len(stops_words_french)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19a17c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_stop_word(doc, stop_words=stops_words_french):\n",
    "    doc = re.sub(r'[\\W_]+', ' ', doc)\n",
    "    return ' '.join([word for word in doc.split() if word.lower() not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a521f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = df.comment.map(delete_stop_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f220b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "wc = WordCloud().generate(' '.join(corpus))\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.title('Word cloud corpus')\n",
    "plt.imshow(wc, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7328d908",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = \" \".join(corpus).split()\n",
    "word_counter = Counter(words)\n",
    "\n",
    "top_100_words = dict(word_counter.most_common(100))\n",
    "\n",
    "wc = WordCloud().generate_from_frequencies(top_100_words)\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.title('Word cloud 100 mots les plus fréquents')\n",
    "plt.imshow(wc, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc7a57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = pd.DataFrame()\n",
    "top_100_words = list(top_100_words)\n",
    "for i in range(1, 11):\n",
    "    tmp_df[f'{1 + (i - 1) * 10} - {i * 10}'] = top_100_words[((i-1)*10) : i*10]\n",
    "tmp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715ee01f",
   "metadata": {},
   "source": [
    "### odds ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd29eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_notes_positives = corpus[df.note >= mean]\n",
    "corpus_notes_negatives = corpus[df.note < mean]\n",
    "\n",
    "class1_words = ' '.join(corpus_notes_positives).split()\n",
    "class2_words = ' '.join(corpus_notes_negatives).split()\n",
    "\n",
    "class1_counter = Counter(class1_words)\n",
    "class2_counter = Counter(class2_words)\n",
    "\n",
    "odds_ratios = {}\n",
    "\n",
    "for word, freq_class1 in class1_counter.items():\n",
    "    freq_class2 = class2_counter[word]\n",
    "    total_words_class1 = sum(class1_counter.values())\n",
    "    total_words_class2 = sum(class2_counter.values())\n",
    "    odds_ratios[word] = ((freq_class1 + 1) / (total_words_class1 + len(class1_counter))) / ((freq_class2 + 1) / (total_words_class2 + len(class2_counter)))\n",
    "\n",
    "sorted_odds_ratios = sorted(odds_ratios.items(), key=lambda x: x[1], reverse=True)\n",
    "top_100_odds_ratios = dict(sorted_odds_ratios[:100])\n",
    "\n",
    "wc = WordCloud().generate_from_frequencies(top_100_odds_ratios)\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.title('Word cloud 100 top odds ratio')\n",
    "plt.imshow(wc, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e178ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_notes_positives = corpus[df.note >= 5]\n",
    "corpus_notes_negatives = corpus[df.note < 5]\n",
    "\n",
    "class1_words = ' '.join(corpus_notes_positives).split()\n",
    "class2_words = ' '.join(corpus_notes_negatives).split()\n",
    "\n",
    "class1_counter = Counter(class1_words)\n",
    "class2_counter = Counter(class2_words)\n",
    "\n",
    "odds_ratios = {}\n",
    "\n",
    "for word, freq_class1 in class1_counter.items():\n",
    "    freq_class2 = class2_counter[word]\n",
    "    total_words_class1 = sum(class1_counter.values())\n",
    "    total_words_class2 = sum(class2_counter.values())\n",
    "    odds_ratios[word] = ((freq_class1 + 1) / (total_words_class1 + len(class1_counter))) / ((freq_class2 + 1) / (total_words_class2 + len(class2_counter)))\n",
    "\n",
    "sorted_odds_ratios = sorted(odds_ratios.items(), key=lambda x: x[1], reverse=True)\n",
    "top_100_odds_ratios = dict(sorted_odds_ratios[:100])\n",
    "\n",
    "wc = WordCloud().generate_from_frequencies(top_100_odds_ratios)\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.title('Word cloud 100 top odds ratio')\n",
    "plt.imshow(wc, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f59755f",
   "metadata": {},
   "source": [
    "### 100 mots les plus frequents par note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66ba47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,11):\n",
    "    corpus_notes = corpus[df.note == i]\n",
    "    words = \" \".join(corpus_notes).split()\n",
    "    word_counter = Counter(words)\n",
    "\n",
    "    top_100_words = dict(word_counter.most_common(100))\n",
    "\n",
    "    wc = WordCloud().generate_from_frequencies(top_100_words)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.title(f'100 mots les plus fréquents - note {i}')\n",
    "    plt.imshow(wc, interpolation='bilinear')\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9501c7db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fa18ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770e39bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3596d280",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5803098",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca93ed5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "4313f96a73e1d93a27cead1ed6cc6585ff33b8c4b927ea6bc0bfc0d0b8d55788"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
